{
    "Type":"ExerciseHomepage",
    "Technology":"MPI",
    "Exercises":[
        {
            "Name":"Hello world",
            "Description":"Producing a hello world is the first test in any language / library / framework you learn. The MPI version of the good old hello world is an application where each MPI process prints its MPI rank and the total number of MPI processes in the global communicator.",
            "DirectoryName":"exercise_1",
            "Difficulty":0
        },
        {
            "Name":"Send a message",
            "Description":"This test is for you to practice the fundamental feature of MPI: sending a message. The application you must develop is made of 2 MPI processes, the first one sends a message and the second one receives it. The message to send is just an integer with the value 12345. The receiver must print the value received. You are free to pick the tag value you want.",
            "DirectoryName":"exercise_2",
            "Difficulty":0
        },
        {
            "Name":"Shout it to the whole world",
            "Description":"This test is an easy way to use a collective operation. This application is made of 4 MPI processes and consists of the MPI process 1 sending the value 12345 to all other MPI processes. To achieve this, you are not allowed to use individual sends, instead you must use a collective operation.",
            "DirectoryName":"exercise_3",
            "Difficulty":0
        },
        {
            "Name":"An incorrect hello world",
            "Description":"Even a hello world can be incorrect; this code demonstrates it. Find the bug and fix it.",
            "DirectoryName":"exercise_4",
            "Difficulty":1
        },
        {
            "Name":"Distributed sum",
            "Description":"A classic collective: the reduction. This exercise consists in writing an application where each process declares a variable containing a value equal to its MPI rank times 100. Then, all processes participate to a collective operation calculating the sum of all these variables and store the sum in a variable held on MPI process 0, which then prints it.",
            "DirectoryName":"exercise_5",
            "Difficulty":1
        },
        {
            "Name":"Switch to non-blocking",
            "Description":"In this test, you are provided with a working code: 2 MPI processes, one sends a message and the other receives it. The objective is simple: make this program use non-blocking operations instead of blocking ones.",
            "DirectoryName":"exercise_6",
            "Difficulty":2
        },
        {
            "Name":"Take as much as you need",
            "Description":"This code makes for a simple application; 2 MPI processes, one sends a message, the other receives it. However, it is an incorrect code and should crash. There might be MPI implementations where this code may not crash, but it does not make it less any incorrect. Find the incorrect statement and fix it.",
            "DirectoryName":"exercise_7",
            "Difficulty":2
        },
        {
            "Name":"Ordered hello world",
            "Description":"The Hello World is the easiest program you can write in MPI. However, one cannot know in which order MPI processes will print their message. The objective here is to write a program that does guarantee that MPI process 0 will write the hello world first, then MPI process 1, then MPI process 2 and so on, for any number of MPI processes.",
            "DirectoryName":"exercise_8",
            "Difficulty":2
        },
        {
            "Name":"Ordered hello world",
            "Description":"This application is made of 3 MPI processes: MPI process 0 holds a 2D array that contains an even number of consecutive integers starting from 0. You must write a program that scatters this array, with a collective operation, such that MPI process 0 receives nothing, MPI process 1 receives all odd numbers and MPI process 2 all even ones.",
            "DirectoryName":"exercise_9",
            "Difficulty":3
        }
    ]
}